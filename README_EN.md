# e-mansion claw & analyzer

## Project Overview

e-mansion claw & analyzer is a Python project designed to scrape comment data from the e-mansion website and analyze these comments using the Gemini API. The goal is to extract advantages, disadvantages, price information, and other valuable insights about real estate properties.

## Project Purpose

This project aims to help users quickly understand user reviews for specific real estate properties. By scraping and analyzing forum comments, it extracts key information to provide a reference for making informed purchasing decisions.

## File Descriptions

* **caller.py**: The main entry point of the program. It is responsible for calling `scraper.py` to scrape comments, `check_comments.py` to verify comment integrity, and `gemini_analyzer.py` to analyze the comments.
* **scraper.py**:  Responsible for scraping web page comments from a specified URL and saving the comment data as a JSON file. It supports incremental scraping to avoid redundant scraping of existing comments.
* **check_comments.py**: Responsible for checking the continuity of comment IDs in the comment JSON file and identifying missing comment IDs. This is used to evaluate the integrity of the scraping results.
* **gemini_analyzer.py**: Responsible for loading comment JSON files and calling the Google Gemini API to analyze the comments. It extracts advantages, disadvantages, price information, and other valuable information about real estate properties, and saves the analysis results as a JSON file.
* **analysis_comments_*.json**: JSON result files generated by Gemini API after analyzing comments. The filename includes a timestamp.
* **comments_*.json**: Raw comment JSON files scraped by `scraper.py`. The filename includes the property ID.

## Usage

1. **Install Dependencies**: Ensure that the following Python libraries are installed:
    ```bash
    pip install requests beautifulsoup4 google-generativeai
    ```
2. **Configure Gemini API Key**:  You need to set the environment variable `GEMINI_API_KEY` to your Gemini API key.
3. **Run `caller.py`**:
    * Running `caller.py` directly will process the default URL list, scrape comments, check for missing IDs, and perform analysis.
      ```bash
      python caller.py
      ```
    * Using the `--check-missing` parameter and filename allows you to check for missing IDs in a specified comment JSON file separately.
      ```bash
      python caller.py --check-missing <filename>
      ```

## `caller.py` Parameter Description

* `--check-missing`: Flag. If set, only checks for missing IDs in the specified file without scraping and analysis.
* `filename`: Optional parameter. When using `--check-missing`, specify the comment JSON filename to be checked.

## Precautions

* Ensure a stable network connection so that the program can access the target forum website and Gemini API.
* Usage of the Gemini API may incur costs. Please be mindful of your API usage quota.
* Avoid excessively frequent scraping to prevent overloading the target website.

## Project Structure

```
property_claw/
├── analysis_comments_*.json
├── caller.py
├── check_comments.py
├── comments_*.json
├── gemini_analyzer.py
├── scraper.py
├── README_EN.md
├── README.md
└── __pycache__/
```

Please modify and improve the README file according to your actual project situation.
